{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os, sys, datetime, pickle\n",
    "import cv2, csv\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "\n",
    "from glob import glob\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,f1_score\n",
    "\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications import VGG19\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_Y_DIR = 'E:/DeepLearning/test5/save_y_pred'\n",
    "RESULTS_HIST_DIR = 'E:/DeepLearning/test5/save_hist'\n",
    "RESULTS_HIST_DIR = 'E:/DeepLearning/test5/save_list'\n",
    "PREFIX_TEST = ['5_1','5_2','5_3','6_1','6_2','6_3','7_1','7_1_1','7_1_2','7_2','7_2_1','7_2_2','7_3','7_3_1','8_1_1', '9_1_1']\n",
    "#PREFIX_TEST = ['8_1_1']\n",
    "SIZE = [75, 128, 256, 320, 384]\n",
    "\n",
    "TEST_FILE = 'E:/DeepLearning/test_file_list.csv'\n",
    "#CLASS_NAME = ['Sugar beet',  'Maize',    'Charlock', 'FatHen',           'Cleavers',     'Loose Silky-bent',\n",
    "#              'Commonwheat',     'Black-grass', 'Small-flowered Cranesbill', 'CommonChickweed', 'Scentless Mayweed', 'Shepherds Purse']\n",
    "CLASS_NAME = ['Black-grass', 'Charlock', 'Cleavers', 'Common Chickweed', 'Common wheat', 'Fat Hen',\n",
    "              'Loose Silky-bent', 'Maize', 'Scentless Mayweed','Shepherds Purse', 'Small-flowered Cranesbill', 'Sugar beet']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "794\n"
     ]
    }
   ],
   "source": [
    "test_file = []\n",
    "with open(TEST_FILE, 'r') as f:\n",
    "    test_file = f.read().split('\\n')\n",
    "while '' in test_file:\n",
    "    test_file.remove('')\n",
    "print(len(test_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>5_1\n",
      "TEST 5_1\n",
      "75,0.9992,0.6695\n",
      "TEST 9 net \n",
      "75,0.7049,0.6885\n",
      ">>>>5_1\n",
      "TEST 5_1\n",
      "128,0.9921,0.7389\n",
      "TEST 9 net \n",
      "128,0.7049,0.6885\n",
      ">>>>5_1\n",
      "TEST 5_1\n",
      "256,0.9971,0.7463\n",
      "TEST 9 net \n",
      "256,0.7049,0.6885\n",
      ">>>>5_1\n",
      "TEST 9 net \n",
      "320,0.7049,0.6885\n",
      ">>>>5_1\n",
      "TEST 5_1\n",
      "384,0.975,0.6663\n",
      "TEST 9 net \n",
      "384,0.7049,0.6885\n",
      ">>>>5_2\n",
      "TEST 5_2\n",
      "75,0.1795,0.1705\n",
      "TEST 9 net \n",
      "75,0.7049,0.6885\n",
      ">>>>5_2\n",
      "TEST 5_2\n",
      "128,0.3516,0.3305\n",
      "TEST 9 net \n",
      "128,0.7049,0.6885\n",
      ">>>>5_2\n",
      "TEST 5_2\n",
      "256,0.5797,0.5253\n",
      "TEST 9 net \n",
      "256,0.7049,0.6885\n",
      ">>>>5_2\n",
      "TEST 9 net \n",
      "320,0.7049,0.6885\n",
      ">>>>5_2\n",
      "TEST 5_2\n",
      "384,0.6505,0.5895\n",
      "TEST 9 net \n",
      "384,0.7049,0.6885\n",
      ">>>>5_3\n",
      "TEST 5_3\n",
      "75,0.1792,0.1716\n",
      "TEST 9 net \n",
      "75,0.7049,0.6885\n",
      ">>>>5_3\n",
      "TEST 5_3\n",
      "128,0.3318,0.3105\n",
      "TEST 9 net \n",
      "128,0.7049,0.6885\n",
      ">>>>5_3\n",
      "TEST 5_3\n",
      "256,0.5811,0.5032\n",
      "TEST 9 net \n",
      "256,0.7049,0.6885\n",
      ">>>>5_3\n",
      "TEST 9 net \n",
      "320,0.7049,0.6885\n",
      ">>>>5_3\n",
      "TEST 9 net \n",
      "384,0.7049,0.6885\n",
      ">>>>6_1\n",
      "TEST 9 net \n",
      "75,0.7049,0.6885\n",
      ">>>>6_1\n",
      "TEST 9 net \n",
      "128,0.7049,0.6885\n",
      ">>>>6_1\n",
      "TEST 6_1\n",
      "256,0.9992,0.8811\n",
      "TEST 9 net \n",
      "256,0.7049,0.6885\n",
      ">>>>6_1\n",
      "TEST 6_1\n",
      "320,0.9987,0.8874\n",
      "TEST 9 net \n",
      "320,0.7049,0.6885\n",
      ">>>>6_1\n",
      "TEST 9 net \n",
      "384,0.7049,0.6885\n",
      ">>>>6_2\n",
      "TEST 9 net \n",
      "75,0.7049,0.6885\n",
      ">>>>6_2\n",
      "TEST 9 net \n",
      "128,0.7049,0.6885\n",
      ">>>>6_2\n",
      "TEST 6_2\n",
      "256,0.5776,0.5547\n",
      "TEST 9 net \n",
      "256,0.7049,0.6885\n",
      ">>>>6_2\n",
      "TEST 6_2\n",
      "320,0.6353,0.6147\n",
      "TEST 9 net \n",
      "320,0.7049,0.6885\n",
      ">>>>6_2\n",
      "TEST 9 net \n",
      "384,0.7049,0.6885\n",
      ">>>>6_3\n",
      "TEST 9 net \n",
      "75,0.7049,0.6885\n",
      ">>>>6_3\n",
      "TEST 9 net \n",
      "128,0.7049,0.6885\n",
      ">>>>6_3\n",
      "TEST 6_3\n",
      "256,0.5674,0.5232\n",
      "TEST 9 net \n",
      "256,0.7049,0.6885\n",
      ">>>>6_3\n",
      "TEST 6_3\n",
      "320,0.5168,0.5211\n",
      "TEST 9 net \n",
      "320,0.7049,0.6885\n",
      ">>>>6_3\n",
      "TEST 9 net \n",
      "384,0.7049,0.6885\n",
      "TEST 9 net \n",
      "75,0.7049,0.6885\n",
      "TEST 9 net \n",
      "128,0.7049,0.6885\n",
      "TEST 9 net \n",
      "256,0.7049,0.6885\n",
      "TEST 7_1 1\n",
      "320,0.9992,0.9147\n",
      "TEST 7_1 2\n",
      "320,0.9992,0.8958\n",
      "TEST 9 net \n",
      "320,0.7049,0.6885\n",
      "TEST 9 net \n",
      "384,0.7049,0.6885\n",
      "TEST 9 net \n",
      "75,0.7049,0.6885\n",
      "TEST 9 net \n",
      "128,0.7049,0.6885\n",
      "TEST 9 net \n",
      "256,0.7049,0.6885\n",
      "TEST 7_1_1 1\n",
      "320,0.9992,0.9147\n",
      "TEST 7_1_1 2\n",
      "320,0.9992,0.8958\n",
      "TEST 9 net \n",
      "320,0.7049,0.6885\n",
      "TEST 9 net \n",
      "384,0.7049,0.6885\n",
      "TEST 9 net \n",
      "75,0.7049,0.6885\n",
      "TEST 9 net \n",
      "128,0.7049,0.6885\n",
      "TEST 9 net \n",
      "256,0.7049,0.6885\n",
      "TEST 7_1_2 1\n",
      "320,0.9992,0.9021\n",
      "TEST 7_1_2 2\n",
      "320,0.9992,0.8937\n",
      "TEST 9 net \n",
      "320,0.7049,0.6885\n",
      "TEST 9 net \n",
      "384,0.7049,0.6885\n",
      "TEST 9 net \n",
      "75,0.7049,0.6885\n",
      "TEST 9 net \n",
      "128,0.7049,0.6885\n",
      "TEST 9 net \n",
      "256,0.7049,0.6885\n",
      "TEST 7_2 1\n",
      "320,0.6403,0.6168\n",
      "TEST 7_2 2\n",
      "320,0.6547,0.6358\n",
      "TEST 9 net \n",
      "320,0.7049,0.6885\n",
      "TEST 9 net \n",
      "384,0.7049,0.6885\n",
      "TEST 9 net \n",
      "75,0.7049,0.6885\n",
      "TEST 9 net \n",
      "128,0.7049,0.6885\n",
      "TEST 9 net \n",
      "256,0.7049,0.6885\n",
      "TEST 7_2_1 1\n",
      "320,0.6403,0.6168\n",
      "TEST 7_2_1 2\n",
      "320,0.6547,0.6358\n",
      "TEST 9 net \n",
      "320,0.7049,0.6885\n",
      "TEST 9 net \n",
      "384,0.7049,0.6885\n",
      "TEST 9 net \n",
      "75,0.7049,0.6885\n",
      "TEST 9 net \n",
      "128,0.7049,0.6885\n",
      "TEST 9 net \n",
      "256,0.7049,0.6885\n",
      "TEST 7_2_2 1\n",
      "320,0.655,0.64\n",
      "TEST 9 net \n",
      "320,0.7049,0.6885\n",
      "TEST 9 net \n",
      "384,0.7049,0.6885\n",
      "TEST 9 net \n",
      "75,0.7049,0.6885\n",
      "TEST 9 net \n",
      "128,0.7049,0.6885\n",
      "TEST 9 net \n",
      "256,0.7049,0.6885\n",
      "TEST 7_3 1\n",
      "320,0.5211,0.4937\n",
      "TEST 9 net \n",
      "320,0.7049,0.6885\n",
      "TEST 9 net \n",
      "384,0.7049,0.6885\n",
      "TEST 9 net \n",
      "75,0.7049,0.6885\n",
      "TEST 9 net \n",
      "128,0.7049,0.6885\n",
      "TEST 9 net \n",
      "256,0.7049,0.6885\n",
      "TEST 7_3_1 1\n",
      "320,0.5211,0.4937\n",
      "TEST 9 net \n",
      "320,0.7049,0.6885\n",
      "TEST 9 net \n",
      "384,0.7049,0.6885\n",
      "TEST 9 net \n",
      "75,0.7049,0.6885\n",
      "TEST 9 net \n",
      "128,0.7049,0.6885\n",
      "TEST 9 net \n",
      "256,0.7049,0.6885\n",
      "TEST 8_1_1 1\n",
      "320,0.9903,0.9537\n",
      "794\n",
      "TEST 8_1_1 2\n",
      "320,0.9934,0.9568\n",
      "794\n",
      "TEST 9 net \n",
      "320,0.7049,0.6885\n",
      "TEST 9 net \n",
      "384,0.7049,0.6885\n",
      ">>>>9_1_1\n",
      "TEST 9 net \n",
      "75,0.7049,0.6885\n",
      ">>>>9_1_1\n",
      "TEST 9 net \n",
      "128,0.7049,0.6885\n",
      ">>>>9_1_1\n",
      "TEST 9 net \n",
      "256,0.7049,0.6885\n",
      ">>>>9_1_1\n",
      "TEST 9 net \n",
      "320,0.7049,0.6885\n",
      ">>>>9_1_1\n",
      "TEST 9 net \n",
      "384,0.7049,0.6885\n"
     ]
    }
   ],
   "source": [
    "for pref_test in PREFIX_TEST:\n",
    "    #print('TEST ' + pref_test)\n",
    "    for size in SIZE:\n",
    "        #print(size)\n",
    "        #print(pref_test + ' ' + str(size))\n",
    "        if '7_1_1' not in pref_test and '7_1_2' not in pref_test and '7_2_1' not in pref_test and '7_2' not in pref_test\\\n",
    "                    and '7_1' not in pref_test and '7_3' not in pref_test \\\n",
    "                    and '7_2_2' not in pref_test and '7_3_1' not in pref_test and '8_1_1' not in pref_test:\n",
    "            print('>>>>' + pref_test)\n",
    "            list_train_results = glob(RESULTS_Y_DIR + '/' + pref_test + '*' + str(size) + '*train*.csv')\n",
    "            list_val_results = glob(RESULTS_Y_DIR + '/' + pref_test + '*' + str(size) + '*val*.csv')\n",
    "            list_test_results = glob(RESULTS_Y_DIR + '/' + pref_test + '*' + str(size) + '*test*.csv')\n",
    "            if len(list_train_results) == 1:\n",
    "                print('TEST ' + pref_test)\n",
    "                with open(list_train_results[0], 'r') as f:\n",
    "                    res_y_train = f.read().split('\\n')\n",
    "                    #print(res_y_train)\n",
    "\n",
    "                    y_true = res_y_train[0].split(',')\n",
    "                    y_pred = res_y_train[1].split(',')\n",
    "                    \n",
    "                    f1_train = np.around(f1_score(y_true, y_pred, average='micro'),4)\n",
    "                    #print('Train F1 ,'   + str(f1))                    \n",
    "\n",
    "                with open(list_val_results[0], 'r') as f:\n",
    "                    res_y_train = f.read().split('\\n')\n",
    "                    #print(res_y_train)\n",
    "\n",
    "                    y_true = res_y_train[0].split(',')\n",
    "                    y_pred = res_y_train[1].split(',')\n",
    "                    \n",
    "                    f1_valid = np.around(f1_score(y_true, y_pred, average='micro'),4)\n",
    "                print(str(size) + ',' +  str(f1_train) + ',' +  str(f1_valid))                      \n",
    "                    \n",
    "                    \n",
    "                test_file_order = glob(RESULTS_HIST_DIR + '/' + pref_test + '*' + str(size) + '*_test_file_list.csv')   \n",
    "                if (len(test_file_order)):\n",
    "                    with open(test_file_order[0], 'r') as f:\n",
    "                        test_file = f.read().split('\\n')\n",
    "                    while '' in test_file:\n",
    "                        test_file.remove('')\n",
    "                    print(len(test_file))                \n",
    "                \n",
    "                    with open(list_test_results[0], 'r') as f:\n",
    "                        res_y_test = f.read()\n",
    "                        #print(res_y_train)\n",
    "                        y_pred_test = res_y_test.split(',')\n",
    "                        #print(len(y_pred_test))\n",
    "                        \n",
    "                        output_file = 'kaggle_' + list_test_results[0].split('\\\\')[-1]\n",
    "                        with open(output_file, 'w') as f1:\n",
    "                            f1.write('file,species\\n')\n",
    "                            for i in range(len(y_pred_test)):\n",
    "                                f1.write(test_file[i] + ',' + CLASS_NAME[int(y_pred_test[i])] + '\\n')\n",
    "                    \n",
    "                    \n",
    "           \n",
    "                hist_val_acc_files = glob(RESULTS_HIST_DIR + '/' + pref_test + '*' + str(size) + '*hist_val_acc')\n",
    "                hist_accuracy_files =  glob(RESULTS_HIST_DIR + '/' + pref_test + '*' + str(size) +'*hist_accuracy')\n",
    "                if len(hist_accuracy_files) != 0:\n",
    "                    with open(hist_accuracy_files[0], \"rb\") as f:\n",
    "                        hist_acc = pickle.load(f)\n",
    "                        #print(hist_acc)\n",
    "                if len(hist_val_acc_files) != 0:\n",
    "                    with open(hist_val_acc_files[0], \"rb\") as f:\n",
    "                        hist_val_acc = pickle.load(f)\n",
    "                        #print(hist_val_acc)                            \n",
    "\n",
    "                \n",
    "        else :\n",
    "            \n",
    "            trial = [1,2]\n",
    "            for t in trial:\n",
    "                \n",
    "                list_train_results = glob(RESULTS_Y_DIR + '/' + pref_test + '*unfrozen' + str(t) + '*' + str(size) + '*train*.csv')\n",
    "                list_val_results = glob(RESULTS_Y_DIR + '/' + pref_test + '*unfrozen' + str(t) + '*' + str(size) + '*val*.csv')\n",
    "                list_test_results = glob(RESULTS_Y_DIR + '/' + pref_test + '*unfrozen' + str(t) + '*' + str(size) + '*test*.csv') \n",
    "                if len(list_train_results):\n",
    "                    print('TEST ' + pref_test + ' ' + str(t))\n",
    "                    with open(list_train_results[0], 'r') as f:\n",
    "                        res_y_train = f.read().split('\\n')\n",
    "                        #print(res_y_train)\n",
    "\n",
    "                        y_true = res_y_train[0].split(',')\n",
    "                        y_pred = res_y_train[1].split(',')\n",
    "\n",
    "                        f1_train = np.around(f1_score(y_true, y_pred, average='micro'),4)\n",
    "                        #print('Train F1 ,'   + str(f1))                    \n",
    "\n",
    "                    with open(list_val_results[0], 'r') as f:\n",
    "                        res_y_train = f.read().split('\\n')\n",
    "                        #print(res_y_train)\n",
    "\n",
    "                        y_true = res_y_train[0].split(',')\n",
    "                        y_pred = res_y_train[1].split(',')\n",
    "\n",
    "                        f1_valid = np.around(f1_score(y_true, y_pred, average='micro'),4)\n",
    "                    print(str(size) + ',' +  str(f1_train) + ',' +  str(f1_valid))            \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    test_file_order = glob(RESULTS_HIST_DIR + '/' + pref_test + '*' + str(size) + '*_test_file_list.csv')   \n",
    "                    if (len(test_file_order)):\n",
    "                        with open(test_file_order[0], 'r') as f:\n",
    "                            test_file = f.read().split('\\n')\n",
    "                        while '' in test_file:\n",
    "                            test_file.remove('')\n",
    "                        print(len(test_file))                \n",
    "\n",
    "                        with open(list_test_results[0], 'r') as f:\n",
    "                            res_y_test = f.read()\n",
    "                            #print(res_y_train)\n",
    "                            y_pred_test = res_y_test.split(',')\n",
    "                            #print(len(y_pred_test))\n",
    "\n",
    "                            output_file = 'kaggle_' + list_test_results[0].split('\\\\')[-1]\n",
    "                            with open(output_file, 'w') as f1:\n",
    "                                f1.write('file,species\\n')\n",
    "                                for i in range(len(y_pred_test)):\n",
    "                                    f1.write(test_file[i] + ',' + CLASS_NAME[int(y_pred_test[i])] + '\\n')\n",
    "                                    \n",
    "                                    \n",
    "        list_train_results = glob(RESULTS_Y_DIR + '/' + '9_1_1_VGG19-trainnet-mask-flavia-imgsize320_train_ypred.csv')\n",
    "        list_val_results = glob(RESULTS_Y_DIR + '/' + '9_1_1_VGG19-trainnet-mask-flavia-imgsize320_val_ypred.csv')\n",
    "        if len(list_train_results):\n",
    "            print('TEST ' + '9 net' + ' ' )\n",
    "            with open(list_train_results[0], 'r') as f:\n",
    "                res_y_train = f.read().split('\\n')\n",
    "                #print(res_y_train)\n",
    "\n",
    "                y_true = res_y_train[0].split(',')\n",
    "                y_pred = res_y_train[1].split(',')\n",
    "\n",
    "                f1_train = np.around(f1_score(y_true, y_pred, average='micro'),4)\n",
    "                #print('Train F1 ,'   + str(f1))                    \n",
    "\n",
    "            with open(list_val_results[0], 'r') as f:\n",
    "                res_y_train = f.read().split('\\n')\n",
    "                #print(res_y_train)\n",
    "\n",
    "                y_true = res_y_train[0].split(',')\n",
    "                y_pred = res_y_train[1].split(',')\n",
    "\n",
    "                f1_valid = np.around(f1_score(y_true, y_pred, average='micro'),4)\n",
    "            print(str(size) + ',' +  str(f1_train) + ',' +  str(f1_valid))    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
